from config import config
import pandas as pd
import numpy as np
from multiprocessing import Pool
from concurrent.futures import ProcessPoolExecutor, wait, FIRST_EXCEPTION
import heapq

import src.classes.save_grid as svgrd
import src.functions.weather as wth
import src.functions.solar as slr
import src.functions.electricity as elc
import src.functions.heat as heat
import src.functions.mobility as mbl


class Grid:
    def __init__(self, settings):
        ### Setup savefile instance which manages data retrieval and saving
        self.settings = settings
        self.SF = svgrd.SaveFile(settings["grid_filename"])

        ### Basic grid data
        self.df_buildings, self.df_region, self.df_weather_raw = self.SF.get_input_data()
        self.region = int(self.df_region["regio7"])        # regiostar region used for mobility statistics
        self.plz = str(self.df_region["plz"]).zfill(5)     # plz of assumed grid position (not of pylovo grid used as representation)
        self.location = {"lat": self.df_region["lat"],     # lattitude of transformer position used for weather data
                         "lon": self.df_region["lon"]}     # longitude of transformer position used for weather data
        self.altitude = self.df_region["altitude"]         # altitude of location in meters

        ### Data to be generated
        if not self.settings["weather_data_exists"]: self.df_weather_raw = pd.DataFrame()
        self.df_supim_solar = pd.DataFrame()
        self.df_demand_elec = pd.DataFrame()
        # self.df_demand_elec_react = pd.DataFrame()
        self.df_demand_heat_space = pd.DataFrame()
        self.df_demand_heat_water = pd.DataFrame()
        self.df_demand_mobility = pd.DataFrame()
        self.df_tve_hpcop = pd.DataFrame()
        self.df_tve_mobility = pd.DataFrame()
        self.battery_dict = {} # Holds mobility battery capacities for every vehicle generated by emobpy {(bus, veh_id): cap, ...}

        ### Urbs output sheets
        self.df_weather_urbs = pd.DataFrame()
        self.df_supim = pd.DataFrame()
        self.df_demand = pd.DataFrame()
        self.df_pro = pd.DataFrame()
        self.df_com = pd.DataFrame()
        self.df_pro_com = pd.DataFrame()
        self.df_sto = pd.DataFrame()
        self.df_tve = pd.DataFrame()
        self.df_bsp = pd.DataFrame()


    ############################################
    ########### Timeseries Generators ########## 
    ############################################
    # The order of these operations has to be followed (e.g. heat depends on electric results)
    def retrieve_weather(self):
        if self.settings["weather_data_exists"]: pass
        else:
            # Get TMY data from SARAH3 dataset as DataFrame
            self.df_weather_raw, self.altitude, selected_months = wth.get_pvgis_tmy_sarah3_dataframe(self.location["lat"], self.location["lon"])
            # Add dew point temperature necessary for vehicle simulation
            self.df_weather_raw["dew_point"] = wth.get_dew_point(self.df_weather_raw["temp_air"], self.df_weather_raw["relative_humidity"])
            # Add soil temperature (1.00-2.55m) necessary for ground source heat pumps
            self.df_weather_raw["soil_temp"] = wth.get_open_meteo_soil_temperature(self.location["lat"], self.location["lon"], selected_months)

    def generate_solar(self):
        # First, obtain missing roof sections with tilt + azimuth
        self.df_buildings = slr.sample_statistics(self.df_buildings)
        
        # Now obtain corresponding solar timeseries
        self.df_supim_solar = slr.create_supim_solar(self.df_buildings[["bus", "roofs"]], self.df_weather_raw, self.location, self.altitude)
    
    def generate_electricity(self):
        # First, assign missing occupation distribution, total demand and use type by statistics
        self.df_buildings = elc.sample_statistics(self.df_buildings)

        # Now obtain electricity demands
        self.df_buildings, self.df_demand_elec = elc.get_elec_demand(self.df_buildings)
        # self.df_demand_elec_react = elc.get_elec_react_demand(self.df_demand_elec)

        # Include daylight saving time effect (electricity timeseries are all UTC+1 only, thus include summer time demand shift):
        # For normal elec demand only after heat, as still needed in this form!  
        # self.df_demand_elec_react = self._add_output_data_daylight_saving_shift(self.df_demand_elec_react)

    def generate_heat(self):
        # First, assign missing building ages
        self.df_buildings = heat.sample_statistics(self.df_buildings)

        # Add daylight saving dummy shift to input data:
        df_wth_input = self._add_input_data_daylight_saving_shift(self.df_weather_raw)
        df_elec_input = self._add_input_data_daylight_saving_shift(self.df_demand_elec)
        self.df_demand_elec = self._add_output_data_daylight_saving_shift(self.df_demand_elec)  # Now we can also adjust elec output data

        # Now, obtain heat demands
        if self.settings["parallel"]:
            # Run parallel jobs
            print(f"Generating heat demands for {len(self.df_buildings)} building(s) with {sum(self.df_buildings["houses_per_building"])} flat(s)...")
            building_subsets = self.partition_df_by_cpu(self.df_buildings, self.settings["n_cpu"], "houses_per_building")
            col_subsets = [[(col, "electricity") for col in subset["bus"].values] for subset in building_subsets]
            job_args = [(subset.reset_index(drop=True), df_elec_input[col_subsets[i]], [np.array(df_wth_input[col]) for col in ["dni", "dhi", "temp_air"]], self.plz)
                         for i, subset in enumerate(building_subsets)]
            with Pool() as pool:
                results = pool.starmap(heat.generate_heat_demands, job_args)
            # Concatenate results
            self.df_demand_heat_space = pd.concat([results[i][0] for i in range(len(results))], axis=1).sort_index(axis=1, level=[0])
            self.df_demand_heat_water = pd.concat([results[i][1] for i in range(len(results))], axis=1).sort_index(axis=1, level=[0])
        else:
            self.df_demand_heat_space, self.df_demand_heat_water = heat.generate_heat_demands(
                            self.df_buildings, df_elec_input, [np.array(df_wth_input[col]) for col in ["dni", "dhi", "temp_air"]], self.plz)

        # Account for daylight saving in output:
        self.df_demand_heat_space = self._add_output_data_daylight_saving_shift(self.df_demand_heat_space)
        self.df_demand_heat_water = self._add_output_data_daylight_saving_shift(self.df_demand_heat_water)

        # Lastly, generate heat pump cops
        self.df_tve_hpcop = heat.generate_hp_cop(self.df_buildings, self.df_demand_heat_space, self.df_demand_heat_water, self.df_weather_raw)

        print("Finished generating heat demands!")

    def generate_mobility(self):
        # First obtain missing BEV distributions over buildings + specs
        self.df_buildings = mbl.sample_statistics(self.df_buildings, self.df_region)
        # Add daylight saving dummy shift to input data
        wth_input = self._add_input_data_daylight_saving_shift(self.df_weather_raw)
        wth_input = mbl.prepare_weather_input(wth_input)
        # Main calculation
        # if self.settings["parallel"]:

        ### Info statement:
        n_cars = self.df_buildings["n_cars_tot"].sum()
        cars_per_cpu = -(-n_cars//self.settings["n_cpu"])
        print(f"Simulating {n_cars} vehicle(s). Expected time {40*cars_per_cpu:.1f} minutes!")

        ### Parallelized run
        if n_cars > 0:
            vehicles = [{key: value} for build_dict in self.df_buildings["car_dict"].values for key,value in build_dict.items()]
            
            # with ProcessPoolExecutor(max_workers=self.settings["n_cpu"]) as executor:
            #     results = list(executor.map(mbl.get_mobility_demand, vehicles, [wth_input.copy()]*len(vehicles)))
            
            with ProcessPoolExecutor(max_workers=self.settings["n_cpu"]) as exe:
                # 1) fire off all jobs
                futures = [exe.submit(mbl.get_mobility_demand, v, wth_input) for v in vehicles]
                # 2) wait until either one fails or all succeed
                done, pending = wait(futures, return_when=FIRST_EXCEPTION)
                # 3) if ANY failed, tear down and re‑raise
                for fut in done:
                    if fut.exception() is not None:
                        exe.shutdown(cancel_futures=True) # cancel the rest
                        raise fut.exception()             # propagate the first error
                # 4) otherwise collect results
                results = [f.result() for f in futures]

            ### Concatenate results
            self.df_demand_mobility = pd.concat([results[i][0] for i in range(len(results))], axis=1)
            self.df_tve_mobility = pd.concat([results[i][1] for i in range(len(results))], axis=1)
            for d in [results[i][2] for i in range(len(results))]: self.battery_dict.update(d)
        # else:
        #     ### Prepare vehicle data in correct input format (concat into one big vehicle dict)
        #     vehicles = {}
        #     self.df_buildings["car_dict"].apply(lambda x: vehicles.update(x))
        #     self.df_demand_mobility, self.df_tve_mobility, self.battery_dict = mbl.get_mobility_demand(vehicles, wth_input)
        
        self.df_demand_mobility = self._add_output_data_daylight_saving_shift(self.df_demand_mobility, mobility_dmd=True)
        self.df_tve_mobility = self._add_output_data_daylight_saving_shift(self.df_tve_mobility)

    ############################################
    ############ Urbs Input Sheets ############# 
    ############################################
    def create_weather_urbs(self):
        df_weather_urbs = self.df_weather_raw[["temp_air", "ghi"]].copy()
        df_weather_urbs.rename(columns={"temp_air":"Tamb", "ghi":"Irradiation"}, inplace=True)
        df_weather_urbs.index.name = "t"
        df_weather_urbs.columns = pd.MultiIndex.from_product([['ambient'], df_weather_urbs.columns])
        self.df_weather_urbs = df_weather_urbs

    def create_supim(self):
        self.df_supim = self.df_supim_solar
        self.df_supim.index.name = "t"
    
    def create_demand(self):
        # self.df_demand = pd.concat([self.df_demand_elec, self.df_demand_elec_react, 
        #                             self.df_demand_heat_space, self.df_demand_heat_water, 
        #                             self.df_demand_mobility], axis=1).reset_index(drop=True)
        self.df_demand = pd.concat([self.df_demand_elec, self.df_demand_heat_space, 
                                    self.df_demand_heat_water, self.df_demand_mobility], axis=1).reset_index(drop=True)
        self.df_demand.index.name = "t"
        
    def create_tve(self):
        self.df_tve = pd.concat([self.df_tve_hpcop, self.df_tve_mobility], axis=1).reset_index(drop=True)
        self.df_tve.index.name = "t"

    def create_bsp(self):
        df_bsp = pd.DataFrame([[config.BSP_IMPORT, config.BSP_FEED_IN]] * len(self.df_supim_solar.index), index=self.df_supim_solar.index, columns=['electricity_import', 'electricity_feed_in'])
        self.df_bsp = df_bsp

    def create_processes(self):
        df_pro_elec = elc.create_pro_elec(list(self.df_buildings["bus"]))
        df_pro_heat = heat.create_pro_heat(list(self.df_buildings["bus"]))
        df_pro_mob = mbl.create_pro_mob(self.battery_dict)
        df_pro_sol = slr.create_pro_solar(self.df_buildings[["bus", "roofs"]])
        
        df_pro = pd.concat([df_pro_elec,df_pro_heat,df_pro_mob,df_pro_sol], axis=0)
        self.df_pro = df_pro.reset_index(drop=True)

    def create_commodities(self):
        df_com_elec = elc.create_com_elec(list(self.df_buildings["bus"]))
        df_com_heat = heat.create_com_heat(list(self.df_buildings["bus"]))
        df_com_mob = mbl.create_com_mob(self.battery_dict)
        df_com_sol = slr.create_com_solar(list(self.df_supim_solar.columns))
        
        df_com = pd.concat([df_com_elec,df_com_heat,df_com_mob,df_com_sol], axis=0)
        self.df_com =  df_com.reset_index(drop=True)   

    def create_process_commodity(self):
        df_pro_com_elec = elc.create_pro_com_elec()
        df_pro_com_heat = heat.create_pro_com_heat()
        df_pro_com_mob = mbl.create_pro_com_mob(self.battery_dict)
        df_pro_com_sol = slr.create_pro_com_solar(list(self.df_supim_solar.columns.get_level_values(1).unique()))
        
        df_pro_com = pd.concat([df_pro_com_elec,df_pro_com_heat,df_pro_com_mob,df_pro_com_sol], axis=0)
        self.df_pro_com = df_pro_com.reset_index(drop=True) 

    def create_storages(self):
        df_sto_elec = elc.create_sto_elec(list(self.df_buildings["bus"]))
        df_sto_heat = heat.create_sto_heat(list(self.df_buildings["bus"]))
        df_sto_mob = mbl.create_sto_mob(self.battery_dict)
        
        df_sto = pd.concat([df_sto_elec,df_sto_heat,df_sto_mob], axis=0)
        self.df_sto = df_sto.reset_index(drop=True) 
    

    ############################################
    ########## Saving all grid data ############ 
    ############################################
    def save_grid_data(self):
        ### Copy input file into results to write results to it:
        self.SF.copy_save_file()

        ### Save other data:
        self.SF.save_df(self.df_weather_raw, "raw_data/weather")
        self.SF.save_df(self.df_buildings,   "raw_data/buildings")

        ### Saving urbs input sheets:
        self.SF.save_df(self.df_demand,      "urbs_in/demand")
        self.SF.save_df(self.df_supim,       "urbs_in/supim")
        self.SF.save_df(self.df_tve,         "urbs_in/eff_factor")
        self.SF.save_df(self.df_bsp,         "urbs_in/buy_sell_price")
        self.SF.save_df(self.df_weather_urbs,"urbs_in/weather")
        self.SF.save_df(self.df_pro,         "urbs_in/process")
        self.SF.save_df(self.df_com,         "urbs_in/commodity")
        self.SF.save_df(self.df_pro_com,     "urbs_in/process_commodity")
        self.SF.save_df(self.df_sto,         "urbs_in/storage")

    ############################################
    ################# Helpers ################## 
    ############################################
    @staticmethod
    def _add_input_data_daylight_saving_shift(df_ts):
        """ To align human behaviour with daylight savings time:
            - Insert a dummy row (later deleted) at 02:00-03:00AM on ts_hour1 (the hour of the year which is skipped), in order to get the human activity of one hour later with the unshifted weather
            - Remove a row (later replaced) at 02:00-03:00AM on ts_hour2 (the hour of the year which is reapeated), in order to realign human activity with weather data
        """
        if len(df_ts)==0: return df_ts.copy()
        else:
            ts_hour1 = 2090 #(= 02:00AM-03:00AM, 29th March 2009), at this position insert previous hour (already accounted for zero indexing)
            ts_hour2 = 7130 #(= 02:00AM-03:00AM, 10th October 2009), at this position delete hour (already accounted for zero indexing)
            df_ts = df_ts.copy()

            ### Delete alignement row
            df_ts = df_ts.drop(index=ts_hour2).reset_index(drop=True)

            ### Insert dummy row:
            new_row = df_ts.iloc[ts_hour1-1].copy()
            new_row_df = pd.DataFrame([new_row], columns=df_ts.columns)
            df_ts = pd.concat([df_ts.iloc[:ts_hour1], new_row_df, df_ts.iloc[ts_hour1:]]).reset_index(drop=True)

            return df_ts

    @staticmethod
    def _add_output_data_daylight_saving_shift(df_ts, mobility_dmd=False):
        """ To align human behaviour with daylight savings time:
            - Now delete the dummy row at 02:00-03:00AM of ts_hour1 (the hour of the year which is skipped), in order to delete the human activity which never actually occured
            - Add a row (simply copy previous timestep) at 02:00-03:00AM of ts_hour2 (the hour of the year which is skipped), in order to get two hours with same human acitivty
            """
        if len(df_ts)==0: return df_ts.copy()
        else:
            ts_hour1 = 2090 #(= 02:00AM-03:00AM, 29th March 2009), at this position delete the dummy row (already accounted for zero indexing)
            ts_hour2 = 7130 #(= 02:00AM-03:00AM, 10th October 2009), at this position copy the previous row and insert below to realign weather with behaviour (already accounted for zero indexing)
            df_ts = df_ts.copy()

            ### Insert copy row:
            new_row = df_ts.iloc[ts_hour2].copy()
            new_row_df = pd.DataFrame([new_row], columns=df_ts.columns)
            df_ts = pd.concat([df_ts.iloc[:ts_hour2+1], new_row_df, df_ts.iloc[ts_hour2+1:]]).reset_index(drop=True)

            # If mobility dataframe, we don't want to copy an existing accumulated demand (would lead to huge demand spike) -> simply set previous copied timestep to 0
            if mobility_dmd: df_ts.iloc[ts_hour2] = 0

            ### Delete dummy row
            df_ts = df_ts.drop(index=ts_hour1).reset_index(drop=True)

        return df_ts
    
    @staticmethod
    def partition_df_by_cpu(df: pd.DataFrame, n_cpus: int, count_column: str ) -> list[pd.DataFrame]:
        """
        Partition the DataFrame `df` (one row per building, with count_column proportional to computational load e.g "n_cars_tot" or "n_flats_tot")
        into up to `n_cpus` subsets, balancing total car counts as evenly as possible
        without splitting any building. If any bin ends up empty, it is dropped from the result.

        Uses the Longest‐Processing‐Time (LPT) greedy heuristic:
        1. Sort buildings by descending `count_column`.
        2. Maintain a min‐heap of (current_load, bin_id) for each of the `n_cpus` bins.
        3. Assign each building to the bin with the smallest load, updating that bin’s load.
        4. After assignment, discard any empty bins.

        Returns:
            A list of pandas DataFrames; each DataFrame is a subset of `df` (same columns/index),
            and no returned DataFrame is empty.
        """
        # 1. Create a list of (index, cars) and sort descending by cars
        building_list = list(df[count_column].items())  # [(idx_0, cars_0), (idx_1, cars_1), ...]
        building_list.sort(key=lambda x: x[1], reverse=True)

        # 2. Initialize a min‐heap [(current_load, bin_id), ...] for bin_id in [0 .. n_cpus-1]
        heap: list[tuple[int, int]] = [(0, bin_id) for bin_id in range(n_cpus)]
        heapq.heapify(heap)

        # 3. Prepare a list of lists to collect row‐indices for each bin
        bins_indices: list[list[pd.Index]] = [[] for _ in range(n_cpus)]

        # 4. Greedily assign each building to the bin with the smallest current load
        for idx, n_count in building_list:
            if n_count == 0: pass
            else:
                current_load, bin_id = heapq.heappop(heap)
                bins_indices[bin_id].append(idx)
                new_load = current_load + n_count
                heapq.heappush(heap, (new_load, bin_id))

        # 5. Convert each non‐empty list of indices into a DataFrame slice
        bins_dfs: list[pd.DataFrame] = []
        for indices_list in bins_indices:
            if not indices_list:
                # Skip any bin that has no assigned buildings
                continue
            subset_df = df.loc[indices_list].copy()
            bins_dfs.append(subset_df)

        return bins_dfs